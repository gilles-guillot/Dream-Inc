---
title: "Industrial failure data analysis"
subtitle: "Dream Inc."
author: "Gilles Guillot"
output: ioslides_presentation
date: "2021-02-03"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r data_reading, include=FALSE}
library(tidyverse)
library(data.table)
source("./Comp_CI_diff_prop.R")
source("./comp_CI_prop.R")


## read csv data file 
label <- read_delim("../label.csv", delim = "|")
label
str(label)
label$treatment <- as.factor(label$treatment)
which(is.na(label$treatment))

outcome <- read_delim("../outcome.csv", delim = "|")
outcome
str(outcome)
which(is.na(outcome$failure))
#outcome$failure <- as.factor(outcome$failure)
#levels(outcome$failure)
table(outcome$failure)
which(outcome$failure==-1)
which(outcome$failure==100)
outcome[outcome$failure==-1 | outcome$failure==100,]
outcome$failure[outcome$failure==-1 | outcome$failure==100] <- NA
# levels(outcome$failure)
# outcome$failure = droplevels(outcome$failure)  

if( sum(label$id != outcome$id) ==0 ){"Row ids are matching"}else
  print("The  hiring committee has a poor sense of humor :)")

dat = tibble(id=label$id,treatment=label$treatment,failure=outcome$failure)
dat

table(dat$treatment,dat$failure)
pA = mean(dat$failure[dat$treatment=="1.4"],na.rm = TRUE)
pB = mean(dat$failure[dat$treatment=="1.5"],na.rm = TRUE)
pA*100
pB*100
(pA-pB)*100

f_test = fisher.test(dat$treatment,dat$failure)

CI_prop_A <- comp_CI_prop(dat$failure[dat$treatment=="1.4"] ,
                               alpha = 0.05, # 1-(nominal coverage)
                               method=c("normal","Wilson","Wilson_cc","CP"))
CI_prop_A

CI_prop_B <- comp_CI_prop(dat$failure[dat$treatment=="1.5"] ,
                               alpha = 0.05, # 1-(nominal coverage)
                               method=c("normal","Wilson","Wilson_cc","CP"))
CI_prop_B

CI_diff_prop <- Comp_CI_diff_prop(e=c(sum(dat$failure[dat$treatment=="1.4"],na.rm = TRUE),
                                      sum(dat$failure[dat$treatment=="1.5"],na.rm = TRUE)),
                                  n= c(length(na.omit(dat$failure[dat$treatment=="1.4"])), 
                                       length(na.omit(dat$failure[dat$treatment=="1.5"]))),
                                  alpha=0.1) 
CI_diff_prop

nrun <- seq(1,3e+6,1000)
Cu <- 43000
cf <- 2.32
Cu/(cf*(pA-pB))
C <- tibble(nrun=nrun,
            mean_update=Cu + cf*nrun*pB,
            min_update= Cu + cf*nrun*CI_prop_B$CI_CP[1],
            max_update= Cu + cf*nrun*CI_prop_B$CI_CP[2],
            mean_no_update= cf*nrun*pA,
            min_no_update= cf*nrun*CI_prop_A$CI_CP[1],
            max_no_update= cf*nrun*CI_prop_A$CI_CP[2],)
C <- C %>% setDT()


C <- melt(C, id=1, measure=patterns("^mean","^min","^max", cols=names(C)), 
     value.name=c("mean","min","max"), variable.name="decision")
C$decision = as.factor(C$decision)
levels(C$decision) <- c("update","no_update")
C  
```

## Observed failure rates
* Set of `r sum(dat$treatment==1.4)` (A) +  `r sum(dat$treatment==1.5)` (B) experiments.

* $p_A=$ `r signif(pA*100,dig=3)`% with version 1.4.

* $p_B=$ `r signif(pB*100,dig=3)`% with version 1.5.

## Uncertainty analysis

* Failure rates estimated on limited samples.

* Uncertainty attached to observed failure rates captured by confidence intervals:
    + $CI_{0.95}(p_A)=$ [ `r signif(100*CI_prop_A$CI_CP[1],3)` `r signif(100*CI_prop_A$CI_CP[2],3)`]
    + $CI_{0.95}(p_B)=$ [ `r signif(100*CI_prop_B$CI_CP[1],3)` `r signif(100*CI_prop_B$CI_CP[2],3)`]
    
    
## Significanc of the association version-failure


* Fisher exact test 

* Null hypothesis: independence of joint distribution (version,failure)

* p-value = `r signif(f_test$p.value,dig=2)`

* We can not rule out the hypothesis that the difference was observed by chance
    
    
    
    
    
    

